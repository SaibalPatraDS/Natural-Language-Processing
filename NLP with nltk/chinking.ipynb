{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f701649-dd7e-4f5a-8963-678f13056e6b",
   "metadata": {},
   "source": [
    "## Chinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f90ca0-185e-4926-969c-76b79e6596f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords,state_union\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888101d0-f81a-4262-aa2d-0fa410d0dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train and test text\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "test_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4c113a-72c7-4831-a170-1fe1e6bed346",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee2d7ba-0caa-4400-a931-4c8eb01d0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('In', 'IN'), ('this', 'DT'), ('decisive', 'JJ'), ('year', 'NN'), (',', ','), ('you', 'PRP'), ('and', 'CC'), ('I', 'PRP'), ('will', 'MD'), ('make', 'VB'), ('choices', 'NNS'), ('that', 'WDT'), ('determine', 'VBP'), ('both', 'DT'), ('the', 'DT'), ('future', 'NN'), ('and', 'CC'), ('the', 'DT'), ('character', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('country', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def pos_tagging_chunking_chinking():\n",
    "    try:\n",
    "        for token in tokenized[13:15]:\n",
    "            words = word_tokenize(token)\n",
    "            pos_tagged = nltk.pos_tag(words)\n",
    "            print(pos_tagged)\n",
    "            chunkGram = r\"\"\"Chunk : {<.*>+}  \n",
    "                               }<VB.?>|<IN><DT><TO>+{\"\"\"  \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(pos_tagged)\n",
    "            chunked.draw()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "pos_tagging_chunking_chinking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79c5b6-fdca-4e1c-ab83-064d3a8a7eaf",
   "metadata": {},
   "source": [
    "*   Chunk:: This is the name of the chunk or chunk label. It's an arbitrary label used to identify the chunk pattern.\n",
    "*   *{<.*>+}: *This specifies a pattern for capturing any sequence of one or more words, regardless of their part-of-speech tags*. The .* * matches any part-of-speech tag, and the + indicates one or more occurrences.\n",
    "*   }<VB.?>|<IN><DT><TO>+{: This part defines cases where the previous pattern should not be considered as a chunk. It specifies two alternative patterns separated by the | symbol:\n",
    "    * <VB.?>: This matches any verb (VB) with an optional suffix (any character .).\n",
    "    * <IN><DT><TO>+: This matches a sequence of preposition (IN), determiner (DT), and infinitive marker (TO) tags. It allows for one or more occurrences (+).\n",
    "\n",
    "    \n",
    "In summary, the chunking grammar pattern captures any sequence of one or more words, except for cases where the sequence contains a verb or a specific sequence of preposition, determiner, and infinitive marker tags. This pattern aims to identify and extract chunks that represent meaningful phrases or groupings in the text, excluding certain patterns that are typically not considered as chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd96f9-5448-415d-9e76-fc059c8f1a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
